{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de começar qualquer análise de dados, é essencial garantir que seus dados estejam limpos e prontos para serem processados. Esta receita fornecerá uma abordagem passo a passo para lidar com valores ausentes, duplicatas e inconsistências em seus dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Passo 1: Identificar Valores Ausentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Carregue o conjunto de dados\n",
    "dados = pd.read_csv('seu_dataset.csv')\n",
    "\n",
    "# Verifique valores ausentes por coluna\n",
    "valores_ausentes = dados.isnull().sum()\n",
    "print(valores_ausentes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decida como lidar com os valores ausentes. Você pode escolher entre remover as linhas ou colunas afetadas, preencher os valores ausentes com médias, medianas ou valores específicos, ou até mesmo imputar com base em métodos mais avançados, como modelos de aprendizado de máquina."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Passo 2: Tratar Valores Ausentes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se você optar por preencher valores ausentes, use métodos como fillna() do pandas. Por exemplo, para preencher com a média da coluna:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preencha valores ausentes com a média da coluna\n",
    "dados['sua_coluna'].fillna(dados['sua_coluna'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Passo 3: Identificar e Remover Duplicatas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identifique duplicatas no conjunto de dados usando .duplicated(). Você pode verificar duplicatas em todo o DataFrame ou em colunas específicas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifique duplicatas no DataFrame inteiro\n",
    "duplicatas = dados[dados.duplicated()]\n",
    "\n",
    "# Ou verifique duplicatas em colunas específicas\n",
    "duplicatas = dados[dados.duplicated(subset=['coluna1', 'coluna2'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remova as duplicatas usando .drop_duplicates()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remova as duplicatas do DataFrame\n",
    "dados_sem_duplicatas = dados.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Passo 4: Lidar com Inconsistências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identifique possíveis inconsistências nos seus dados. Isso pode incluir valores que não fazem sentido no contexto do seu problema.\n",
    "\n",
    "Para corrigir inconsistências, você pode aplicar transformações específicas ou remover as linhas com dados inconsistentes, dependendo da natureza do problema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Passo 5: Salvar os Dados Limpos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, depois de concluir o processo de limpeza, salve seus dados limpos em um novo arquivo para uso posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salve os dados limpos em um novo arquivo CSV\n",
    "dados_sem_duplicatas.to_csv('dados_limpos.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, você tem um conjunto de dados mais limpo e pronto para análise. Lembre-se de que a limpeza de dados é uma etapa crítica em qualquer projeto de análise de dados, pois dados sujos podem levar a conclusões errôneas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
